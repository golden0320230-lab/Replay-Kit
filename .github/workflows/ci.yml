name: ci

on:
  push:
    branches: ["main"]
  pull_request:

jobs:
  test-and-assert:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Test
        run: |
          python -m pytest -q

      - name: Example App Smoke
        run: |
          python examples/apps/minimal_app.py

      - name: Golden Path Record/Replay/Assert/Diff
        run: |
          python -c "from pathlib import Path; Path('runs/golden').mkdir(parents=True, exist_ok=True)"
          python -m replaypack record --out runs/golden/target.rpk -- python examples/apps/minimal_app.py
          python -m replaypack replay runs/golden/target.rpk --out runs/golden/replay-a.rpk --seed 7 --fixed-clock 2026-02-22T00:00:00Z
          python -m replaypack replay runs/golden/target.rpk --out runs/golden/replay-b.rpk --seed 7 --fixed-clock 2026-02-22T00:00:00Z
          python -m replaypack assert runs/golden/replay-a.rpk --candidate runs/golden/replay-b.rpk --json > runs/golden/assert-determinism.json
          python -m replaypack diff runs/golden/replay-a.rpk runs/golden/replay-a.rpk --json > runs/golden/diff-self.json
          echo "Golden path deterministic checks completed (runs/golden/*)."

      - name: Golden Path Replay Network Guard
        run: |
          python -m pytest -q tests/test_e2e_record_replay_assert.py

      - name: Replay Assertion
        run: |
          python -c "from pathlib import Path; Path('runs').mkdir(parents=True, exist_ok=True)"
          python -m replaypack assert examples/runs/m2_capture_boundaries.rpk --candidate examples/runs/m2_capture_boundaries.rpk --json > runs/ci-assert.json
          echo "CI assertion output written to runs/ci-assert.json"

      - name: Benchmark Suite
        run: |
          python -c "from pathlib import Path; Path('runs').mkdir(parents=True, exist_ok=True)"
          python -m replaypack benchmark --source examples/runs/m2_capture_boundaries.rpk --iterations 2 --out runs/ci-benchmark.json --json > runs/ci-benchmark-result.json
          python -m replaypack benchmark --source examples/runs/m2_capture_boundaries.rpk --iterations 2 --out runs/ci-benchmark-gated.json --baseline runs/ci-benchmark.json --fail-on-slowdown 500 --json > runs/ci-benchmark-gate.json
          echo "Benchmark outputs written under runs/"

      - name: Cross-Platform Hash Parity
        run: |
          python -c "from pathlib import Path; Path('runs/parity').mkdir(parents=True, exist_ok=True)"
          python -m replaypack.ci_parity --source examples/runs/m2_capture_boundaries.rpk --out-dir runs/parity --expected ci/expected_hash_parity.json --json > runs/parity/ci-hash-parity.json
          echo "Parity output written to runs/parity/ci-hash-parity.json"

      - name: Upload Replay Artifacts
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: replay-artifacts-${{ matrix.os }}
          path: runs/
          if-no-files-found: ignore
